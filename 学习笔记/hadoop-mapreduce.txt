mapreduce  hadoop中cpu的使用率
mapreduce 的编程模型

zcat 压缩文件.gz 直接解压缩打开

气象原始数据-> 处理数据->输出
用（map-reduce）处理数据 
1. 格式           //map阶段开始
(0,12461685)     //(行数，数据内容)
2. 进一步抽取数据 （年份：温度）
（2010，12）
（2010，45）
（2012，23）
...
3.合并同一年的数据（2010，[12,45]）
4.抽取同一年中数据的最大值（2010，45） //reduce阶段开始

map-reduce 的核心思想 分而治理  
mapper把复杂的任务分解为若干个“简单的任务”执行
1.缩小计算规模
2.就近分配到数据节点进行计算
3.多个小任务可以并行计算

reducer
对map的结果进行汇总
reducer的数目由mapred-site.xml配置文件里的项目mapred.reduce.tasks决定，缺省值=1 


shtffer 是mapper和reducer中间的一个步骤（根据需求决定，一般在复杂的计算中会用到）
把mapper的输出值根据关键字进行分解，重组，提取，把结果发送reduce在进行处理，来提升reduce的使用效率


Hadoop处理上G大小的数据文件反而比处理成千上万的小文件要更好




















